# RAG LLM Template

A comprehensive, production-ready template for building Retrieval-Augmented Generation (RAG) applications with multiple LLM providers, vector databases, and a modern FastAPI backend.

## Features

### ğŸš€ **Multi-Provider LLM Support**
- **Azure OpenAI** (default)
- **OpenAI**
- **Anthropic Claude**
- **Google Gemini**
- **Local Models** (extensible)

### ğŸ§  **Flexible Embedding Services**
- **Local Embeddings** (sentence-transformers, default)
- **OpenAI Embeddings**
- **Azure OpenAI Embeddings**

### ğŸ—„ï¸ **Dual Database Architecture**
- **ChromaDB** for vector storage and NoSQL operations
- **PostgreSQL** for relational data (users, conversations, metadata)
- **Redis** for caching and session management

### ğŸ“š **Document Processing**
- Support for PDF, DOCX, TXT, and Markdown files
- Intelligent text chunking with overlap
- Automatic metadata extraction
- File upload validation and security

### ğŸ” **Authentication & Authorization**
- JWT-based authentication
- Role-based access control (Admin, User, Viewer)
- Secure password hashing with bcrypt
- Session management

### ğŸ›ï¸ **RAG Configuration**
- Toggle vector search on/off per conversation
- Configurable similarity thresholds
- Adjustable chunk retrieval limits
- Custom prompts and system messages

### ğŸ³ **Production Ready**
- Docker Compose orchestration
- Health checks and monitoring
- Comprehensive logging
- Error handling and validation
- Structured configuration management

## Quick Start

### Prerequisites
- Docker and Docker Compose
- Git

### 1. Clone the Repository
```bash
git clone <repository-url>
cd rag-llm-template
```

### 2. Environment Configuration
```bash
# Copy the example environment file
cp .env.example .env

# Edit the environment file with your settings
nano .env
```

**Required Configuration:**
```bash
# Azure OpenAI (default LLM provider)
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4

# Database
DATABASE_URL=postgresql://postgres:password@db:5432/ragllm

# Security
SECRET_KEY=your-secret-key-here
```

### 3. Start the Application
```bash
# Build and start all services
docker compose up --build

# Or run in detached mode
docker compose up --build -d
```

> **Note:** This template is configured for direct access on port 8000 for internal testing. For production deployments with nginx reverse proxy, see `docker/README_nginx.md`.

### 4. Access the Application
- **API Documentation:** http://localhost:8000/docs
- **Health Check:** http://localhost:8000/health
- **Application:** http://localhost:8000

## Architecture

### Directory Structure
```
rag-llm-template/
â”œâ”€â”€ app/                    # Main application code
â”‚   â”œâ”€â”€ auth/              # Authentication services
â”‚   â”œâ”€â”€ db/                # Database models and connections
â”‚   â”œâ”€â”€ embeddings/        # Embedding services
â”‚   â”œâ”€â”€ enums/             # Enumerations
â”‚   â”œâ”€â”€ generation/        # LLM services and chat logic
â”‚   â”œâ”€â”€ ingestion/         # Document processing
â”‚   â”œâ”€â”€ middleware/        # FastAPI middleware
â”‚   â”œâ”€â”€ prompts/           # System prompts and templates
â”‚   â”œâ”€â”€ retrieval/         # Vector search and retrieval
â”‚   â”œâ”€â”€ schema/            # Pydantic schemas
â”‚   â”œâ”€â”€ utils/             # Utility functions
â”‚   â”œâ”€â”€ views/             # API endpoints
â”‚   â””â”€â”€ main.py           # FastAPI application
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ documents/         # Uploaded documents
â”‚   â”œâ”€â”€ vector_store/      # ChromaDB data
â”‚   â””â”€â”€ db/               # Database files
â”œâ”€â”€ docker/               # Docker configuration
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ migrations/           # Database migrations
â”œâ”€â”€ Notebooks/            # Jupyter notebooks
â”œâ”€â”€ tests/               # Test files
â”œâ”€â”€ docker-compose.yml   # Docker services
â”œâ”€â”€ Dockerfile           # Application container
â””â”€â”€ requirements.txt     # Python dependencies
```

## Changelog

### v1.0.0
- Initial release
- Multi-provider LLM support
- Vector search with ChromaDB
- Authentication and authorization
- Document processing pipeline
- Docker Compose deployment
